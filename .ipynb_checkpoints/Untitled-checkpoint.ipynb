{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection for Auto Driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is provided by [drive.ai](https://www.drive.ai/). Images were gathered from cameras mounted to the front of cars. We want to use YOLO algorithm to recognize objects in images. Recognized objects are labelled by a square box. In the notebook, I did following:\n",
    "- F\n",
    "- max\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of a box\n",
    "$b_x$ and $b_y$ define center of box and $b_h$ and $b_w$ define size of box. If there are 80 categories to recognize, I can either represent the category of object by:\n",
    "- $i)$ label c as an integer from 1 to 80: 6 elements to represent a box\n",
    "- $ii)$ one hot vector with $c_{th} $ place as 1 and all others as 0s: 85 elements to represent a box\n",
    "\n",
    "<img src=\"nb_images/box_label.png\" style=\"width:500px;height:250;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO (\"you only look once\") requires only one forward propagation pass through the network to make predictions. Thus it \"only looks once\" at the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model details\n",
    "\n",
    "- The **input** is m images in tensor of shape (m, 608, 608, 3)\n",
    "- The **output** is a list of boxes along with the recognized classes (m, 19, 19, 5, 85). Each image is cut into 19*19 cells. Each cell has five boxes. Each bounding box is represented by 6 numbers $(p_c, b_x, b_y, b_h, b_w, c)$ as explained above. If $c$ is expanded into an 80-dimensional vector, each bounding box is then represented by 85 numbers. \n",
    "\n",
    "If the center/midpoint of an object falls into a grid cell, that grid cell is responsible for detecting that object. A cell can have maximum of 5 objects centered inside.\n",
    "\n",
    "YOLO architecture: IMAGE (m, 608, 608, 3) -> DEEP CNN -> ENCODING (m, 19, 19, 5, 85).\n",
    "\n",
    "<img src=\"nb_images/architecture.png\" style=\"width:700px;height:400;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Filtering boxes with class scores\n",
    "\n",
    "Each cell gives 5 boxes. So the model can predict 19x19x5=1805 boxes by just looking once at the image. So we need\n",
    "- First, only keep boxes with high class score (more confident about detecting an object)\n",
    "- Second, only keep one box when several overlapping boxes are detecting the same object\n",
    "<img src=\"nb_images/anchor_map.png\" style=\"width:200px;height:200;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yolo_filter_boxes( box_confidence, boxes, box_class_probs, threshold)** will filter boxes:\n",
    "\n",
    "Step 1:\n",
    "Scores of every class are calculated by $p_c$ * ($c_1$, $c_2$, ..., $c_{79}$, $c_{80}$)\n",
    "- \"box_confidence\" is $p_c$, a tensor of shape (19, 19, 5, 1)\n",
    "- \"box_class_probs\" is ( $c_1$, $c_2$, ..., $c_{79}$, $c_{80}$), a tensor of shape (19, 19, 5, 80)\n",
    "- \"boxes\" is sizes of all the boxes, containing $(b_x, b_y, b_h, b_w)$, a tensor of shape (19, 19, 5, 4)\n",
    "\n",
    "Step 2:\n",
    "In every box, find the index and value of class with max score. Index is saved as \"box_classes\" and value is saved as \"box_class_scores\". Create a filtering mask based on \"box_class_scores\" by using \"threshold\".\n",
    "\n",
    "Step 3:\n",
    "Apply filtering mask to all boxes and got boxes with scores higher than threshold.\n",
    "- \"scores\" -- tensor of shape (number_selected_boxes, 1), containing the class probability score for selected boxes\n",
    "- \"boxes\" -- tensor of shape (number_selected_boxes, 4), containing $(b_x, b_y, b_h, b_w)$ coordinates of selected boxes\n",
    "- \"classes\" -- tensor of shape (number_selected_boxes, 1), containing the index of the class detected by the selected boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    # Step 1: Compute box scores.\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    \n",
    "    # Step 2: find the index and value of class with max score.\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1, keepdims=False)\n",
    "    # Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep \n",
    "    filtering_mask = box_class_scores>=threshold\n",
    "    \n",
    "    # Step 3: Apply the mask to scores, boxes and classes, select box with score higher than threshold\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
